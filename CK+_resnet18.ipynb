{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CK+_resnet18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8w3Ftr_Ox_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXuqfoxUO2B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKvXStzkO3no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/FER\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7jnxS19O3tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9fXVi4vSVQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLqt6KulWj6O",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WFtnRpcPiOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCRqo85IVAKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedResNet(nn.Module):\n",
        "  def __init__(self, num_classes, feature_extracting):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    \n",
        "    #TODO1: Load pre-trained ResNet Model\n",
        "    self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "    #Set gradients to false\n",
        "    if feature_extracting:\n",
        "      for param in self.resnet18.parameters():\n",
        "          param.requires_grad = False\n",
        "    \n",
        "    #Replace last fc layer\n",
        "    num_feats = self.resnet18.fc.in_features\n",
        "    \n",
        "    #TODO2: Replace fc layer in resnet to a linear layer of size (num_feats, num_classes)\n",
        "    self.resnet18.fc = torch.nn.Linear(num_feats, num_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #TODO3: Forward pass x through the model\n",
        "    x = self.resnet18(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjYBg1gOidRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from os.path import isfile, join\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rkv-hoShyyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = 'training/'\n",
        "emotion_list = ['anger', 'disgust', 'fear', 'happy', 'sadness', 'surprise', 'contempt']\n",
        "img_list = []\n",
        "train_lab = []\n",
        "\n",
        "count = 0\n",
        "ct = 0\n",
        "for emotion in emotion_list:\n",
        "  mypath = PATH + '/' + emotion\n",
        "  files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  for file in files:\n",
        "    file_path = mypath + '/' + file\n",
        "    img = cv2.imread(file_path, 0)\n",
        "    #print(img.shape)\n",
        "    ct += 1\n",
        "    #print(ct)\n",
        "    img = np.repeat(img, 3)\n",
        "    img = img.reshape((48, 48, 3))\n",
        "    img_list.append(img)\n",
        "    train_lab.append(count)\n",
        "  count += 1\n",
        "\n",
        "img_arr = np.array(img_list)\n",
        "#print(img_arr.shape)\n",
        "train_val = img_arr\n",
        "train_lab = np.array(train_lab)\n",
        "#print(test_lab.shape)\n",
        "\n",
        "PATH = 'testing/'\n",
        "emotion_list = ['anger', 'disgust', 'fear', 'happy', 'sadness', 'surprise', 'contempt']\n",
        "img_list = []\n",
        "test_lab = []\n",
        "\n",
        "count = 0\n",
        "ct = 0\n",
        "for emotion in emotion_list:\n",
        "  mypath = PATH + '/' + emotion\n",
        "  files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "  for file in files:\n",
        "    file_path = mypath + '/' + file\n",
        "    img = cv2.imread(file_path, 0)\n",
        "    #print(img.shape)\n",
        "    ct += 1\n",
        "    #print(ct)\n",
        "    img = np.repeat(img, 3)\n",
        "    img = img.reshape((48, 48, 3))\n",
        "    img_list.append(img)\n",
        "    test_lab.append(count)\n",
        "  count += 1\n",
        "\n",
        "img_arr = np.array(img_list)\n",
        "#print(img_arr.shape)\n",
        "test_val = img_arr\n",
        "test_lab = np.array(test_lab)\n",
        "#print(test_lab.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O72L2JEFTuDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_lab.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXaNx90YhIty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformations = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "trainset = CK(transform=transformations)\n",
        "trainset_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                                    batch_size=8,\n",
        "                                                    shuffle=True, num_workers=4)\n",
        "\n",
        "testset = CK(transform=transformations)\n",
        "testset_loader = torch.utils.data.DataLoader(dataset=testset,\n",
        "                                                    batch_size=8,\n",
        "                                                    shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKvxxpjrhXOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CK(torch.utils.data.Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "    self.transform = transform\n",
        "    self.train_data = train_val\n",
        "    self.train_label = train_lab\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    train_instance = self.train_data[index]\n",
        "    train_img = Image.fromarray(train_instance)\n",
        "    train_img = train_img.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      train_tensor = self.transform(train_img)\n",
        "    return (train_tensor, self.train_label[index])\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKeoZDpjEPSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, epoch, num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  epoch_acc = 0.0\n",
        "  \n",
        "  for batch_idx, (images, labels) in enumerate(trainset_loader):\n",
        "    #zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #move to GPU\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    \n",
        "    #forward\n",
        "    outputs = model.forward(images)\n",
        "#     print(labels)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "#     print(\"loss: \" + str(loss))\n",
        "    \n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += torch.sum(preds == labels).item()\n",
        "    \n",
        "  epoch_loss /= train_lab.shape[0]\n",
        "  epoch_acc /= train_lab.shape[0]\n",
        "  \n",
        "  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))\n",
        "\n",
        "# for i, (images, labels) in enumerate(dataset_loader):\n",
        "#   print(len(images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfEFHqEB32yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 15\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 8\n",
        "RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n",
        "\n",
        "#Initialize the model\n",
        "CK_model = PreTrainedResNet(7, RESNET_LAST_ONLY)\n",
        "CK_model = CK_model.cuda()\n",
        "\n",
        "#Setting the optimizer and loss criterion\n",
        "optimizer = optim.SGD(CK_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Begin Train\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train(CK_model, optimizer, criterion, epoch+1, NUM_EPOCHS)\n",
        "  \n",
        "print(\"Finished Training\")\n",
        "print(\"-\"*10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QynJt9lcUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  \n",
        "  label_arr = []\n",
        "  pred_arr = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(testset_loader):\n",
        "        #move to GPU\n",
        "        \n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        if itr==1:\n",
        "          label = np.array(labels.cpu())\n",
        "          label_arr.extend(label)\n",
        "          \n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        \n",
        "        if itr==1:\n",
        "          pred = np.array(preds.cpu())\n",
        "          pred_arr.extend(pred)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "\n",
        "    test_loss /= (test_lab.shape[0]*repeats)\n",
        "    test_acc /= (test_lab.shape[0]*repeats)\n",
        "\n",
        "    print('Test Loss: %.4f Test Accuracy %.4f' % (test_loss, test_acc))\n",
        "    \n",
        "  return label_arr, pred_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DfplcjodtC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab, pre = test(CK_model,criterion, repeats=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9SFNSykkU1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(lab, pre)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U04H3nXvzhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(model, criterion, repeats = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkEH25MDSpxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install face_recognition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9Dtrr0SZxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orguKYDPDbpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect(image):\n",
        "    if image.shape[2] != 3:\n",
        "        print('...')\n",
        "\n",
        "\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(rgb,\n",
        "    \tmodel = 'cnn')\n",
        "    print(boxes)\n",
        "    images = []\n",
        "    for box in boxes:\n",
        "        img = image[box[0] : box[2] , box[3] : box[1]]\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        images.append(gray)\n",
        "        \n",
        "    for image in images:\n",
        "      print(image)\n",
        "      cv2_imshow(image)\n",
        "        \n",
        "    new_images = []\n",
        "    for image in images:\n",
        "      shape = np.shape(image)\n",
        "      new_image = np.repeat(image, 3)\n",
        "      new_image = new_image.reshape((shape[0], shape[1], 3)).astype('uint8')\n",
        "      new_images.append(new_image)\n",
        "\n",
        "    return new_images, boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9XbQu_HDd59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = cv2.imread('test.jpg')\n",
        "faces, boxes = np.array(detect(test_img))\n",
        "print(np.shape(faces[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bIVrSlIDf9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class test_image(torch.utils.data.Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "    self.transform = transform\n",
        "    test_img = cv2.imread('test.jpg')\n",
        "    faces, boxes = np.array(detect(test_img))\n",
        "    self.data = faces\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    instance = self.data[index]\n",
        "    img = Image.fromarray(instance)\n",
        "    img = img.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      instance_tensor = self.transform(img)\n",
        "    return instance_tensor\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGumvS7JDt-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "with torch.no_grad():\n",
        "  for batch_idx, images in enumerate(dataset_loader):\n",
        "#   outputs = model.forward(images)\n",
        "#   print(outputs)\n",
        "    print(np.shape(np.array(images)))\n",
        "    images = images.cuda()\n",
        "    outputs = model.forward(images)\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    pred1 = preds.cpu()\n",
        "    print(np.array(pred1))\n",
        "    labels.extend(np.array(pred1))\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22p8J2LD2CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "face_list = []\n",
        "for ((top, right, bottom, left), label) in zip(boxes, labels):\n",
        "  cv2.rectangle(test_img, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "  y = top - 15 if top - 15 > 15 else top + 15\n",
        "  cv2.putText(test_img, class_list[label], (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.75, (0, 255, 0), 2)\n",
        "  face_list.append((label, ((top+bottom)/2, (left+right)/2)))\n",
        "\n",
        "print(face_list)\n",
        "# cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "im2 = test_img.copy()\n",
        "# im2[:,:,0] = test_img[:,:,2]\n",
        "# im2[:, :, 2] = test_img[:, :, 0]\n",
        "scipy.misc.imsave('kkk.jpg', im2)\n",
        "cv2_imshow(im2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}