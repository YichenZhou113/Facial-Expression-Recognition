{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8w3Ftr_Ox_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXuqfoxUO2B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKvXStzkO3no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/facial_expression_data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7jnxS19O3tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnftKrnO9Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMg8ZI99Uk-S",
        "colab_type": "text"
      },
      "source": [
        "#Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvnoU_McPAKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "a = torch.Tensor([1]).cuda()\n",
        "print(a)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9fXVi4vSVQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8dxN-06elWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_split_train_test(data_dir):\n",
        "    train_values = []\n",
        "    train_labels = []\n",
        "    val_values = []\n",
        "    val_labels = []\n",
        "    test_values = []\n",
        "    test_labels = []\n",
        "  \n",
        "    with open(data_dir,'r') as csvin:\n",
        "      data=csv.reader(csvin)\n",
        "    \n",
        "      for row in data:\n",
        "#       training, val and test set are already indicated in the csv file by the last attribute\n",
        "        if row[-1] == 'Training':\n",
        "          value = row[1]\n",
        "          temp_train_row = []\n",
        "          for pixel_value in value.split(' '):\n",
        "            temp_train_row.append(int(pixel_value))\n",
        "          temp_train_row = np.array(temp_train_row)\n",
        "          temp_train_row = np.repeat(temp_train_row, 3)\n",
        "          temp_train_row = temp_train_row.reshape((48, 48, 3)).astype('uint8')\n",
        "          train_values.append(temp_train_row)\n",
        "          train_labels.append(row[0])\n",
        "        if row[-1] == 'PrivateTest':\n",
        "          value = row[1]\n",
        "          temp_val_row = []\n",
        "          for pixel_value in value.split(' '):\n",
        "            temp_val_row.append(int(pixel_value))\n",
        "          temp_val_row = np.array(temp_val_row)\n",
        "          temp_val_row = np.repeat(temp_val_row, 3)\n",
        "          temp_val_row = temp_val_row.reshape((48, 48, 3)).astype('uint8')\n",
        "          val_values.append(temp_val_row)\n",
        "          val_labels.append(row[0])\n",
        "        if row[-1] == 'PublicTest':\n",
        "          value = row[1]\n",
        "          temp_test_row = []\n",
        "          for pixel_value in value.split(' '):\n",
        "            temp_test_row.append(int(pixel_value))\n",
        "          temp_test_row = np.array(temp_test_row)\n",
        "          temp_test_row = np.repeat(temp_test_row, 3)\n",
        "          temp_test_row = temp_test_row.reshape((48, 48, 3)).astype('uint8')\n",
        "          test_values.append(temp_test_row)\n",
        "          test_labels.append(row[0])\n",
        "        \n",
        "    train_values = np.array(train_values, dtype='uint8')\n",
        "    train_labels = np.array(train_labels, dtype='int')\n",
        "    val_values = np.array(val_values, dtype='uint8')\n",
        "    val_labels = np.array(val_labels, dtype='int')\n",
        "    test_values = np.array(test_values, dtype='uint8')\n",
        "    test_labels = np.array(test_labels, dtype='int')\n",
        "    \n",
        "    return train_values, train_labels, val_values, val_labels, test_values, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUGPuV-ci4bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [1,2,3]\n",
        "x = np.array(x)\n",
        "x = np.repeat(x, 3)\n",
        "x = np.reshape(x, (3, 3))\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF7zTvwwemwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_values, train_labels, val_values, val_labels, test_values, test_labels = load_split_train_test('data/fer2013.csv')\n",
        "print(train_values[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VPO1qVmmt8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(train_values[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW8qMz7Pf0Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img = Image.fromarray(train_values[0])\n",
        "# train_img = transforms.Resize(224)\n",
        "train_img = train_img.convert('RGB')\n",
        "print(train_img)\n",
        "train_img.save(\"sample2.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLqt6KulWj6O",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WFtnRpcPiOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5tYCwegdtGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class fer2013_dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, transform=None, partition='train'):\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "    self.transform = transform\n",
        "    self.partition = partition\n",
        "    self.data_info = pd.read_csv('data/fer2013.csv', header=None)\n",
        "    train_values, train_labels, val_values, val_labels, test_values, test_labels = load_split_train_test('data/fer2013.csv')\n",
        "    self.train_data = train_values\n",
        "    self.train_label = train_labels\n",
        "    self.val_data = val_values\n",
        "    self.val_labels = val_labels\n",
        "    self.test_data = test_values\n",
        "    self.test_labels = test_labels\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    if self.partition == 'train':\n",
        "      train_instance = self.train_data[index]\n",
        "      train_img = Image.fromarray(train_instance)\n",
        "      train_img = train_img.convert('RGB')\n",
        "      if self.transform is not None:\n",
        "        train_tensor = self.transform(train_img)\n",
        "      return (train_tensor, self.train_label[index])\n",
        "      \n",
        "    if self.partition == 'val':\n",
        "      val_instance = self.val_data[index]\n",
        "      val_img = Image.fromarray(val_instance)\n",
        "      val_img = val_img.convert('RGB')\n",
        "      if self.transform is not None:\n",
        "        val_tensor = self.transform(val_img)\n",
        "      return (val_tensor, self.val_labels[index])\n",
        "    \n",
        "    if self.partition == 'test':\n",
        "      test_instance = self.test_data[index]\n",
        "      test_img = Image.fromarray(test_instance)\n",
        "      test_img = test_img.convert('RGB')\n",
        "      if self.transform is not None:\n",
        "        test_tensor = self.transform(test_img)\n",
        "      return (test_tensor, self.test_labels[index])\n",
        "    \n",
        "  def __len__(self):\n",
        "    if self.partition == 'train':\n",
        "      return len(self.train_label)\n",
        "    if self.partition == 'val':\n",
        "      return len(self.val_labels)\n",
        "    if self.partition == 'test':\n",
        "      return len(self.test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8gmJNGzlL75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformations = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "dataset = fer2013_dataset(transform=transformations, partition='train')\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                                    batch_size=64,\n",
        "                                                    shuffle=True, num_workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIREpVGaqPJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = fer2013_dataset(transform=transformations, partition='val')\n",
        "val_loader = torch.utils.data.DataLoader(val,\n",
        "                                                    batch_size=64,\n",
        "                                                    shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrh__Zr1qS8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = fer2013_dataset(transform=transformations, partition='test')\n",
        "test_loader = torch.utils.data.DataLoader(test,\n",
        "                                                    batch_size=64,\n",
        "                                                    shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G199mu-UrDMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "  print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCRqo85IVAKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedResNet(nn.Module):\n",
        "  def __init__(self, num_classes, feature_extracting):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    \n",
        "    #TODO1: Load pre-trained ResNet Model\n",
        "    self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "    #Set gradients to false\n",
        "    if feature_extracting:\n",
        "      for param in self.resnet18.parameters():\n",
        "          param.requires_grad = False\n",
        "    \n",
        "    #Replace last fc layer\n",
        "    num_feats = self.resnet18.fc.in_features\n",
        "    \n",
        "    #TODO2: Replace fc layer in resnet to a linear layer of size (num_feats, num_classes)\n",
        "    self.resnet18.fc = torch.nn.Linear(num_feats, num_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #TODO3: Forward pass x through the model\n",
        "    x = self.resnet18(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_NYa7M7lbsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, epoch, num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  epoch_acc = 0.0\n",
        "  \n",
        "  for batch_idx, (images, labels) in enumerate(dataset_loader):\n",
        "    #zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #move to GPU\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    \n",
        "    #forward\n",
        "    outputs = model.forward(images)\n",
        "#     print(labels)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "#     print(\"loss: \" + str(loss))\n",
        "    \n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += torch.sum(preds == labels).item()\n",
        "    \n",
        "  epoch_loss /= 28709\n",
        "  epoch_acc /= 28709\n",
        "  \n",
        "  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))\n",
        "  \n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "# for i, (images, labels) in enumerate(dataset_loader):\n",
        "#   print(len(images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CriUH48WVL5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 64\n",
        "RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n",
        "\n",
        "#Initialize the model\n",
        "model = PreTrainedResNet(7, RESNET_LAST_ONLY)\n",
        "model = model.cuda()\n",
        "joblib.dump(model, 'model.pkl')\n",
        "\n",
        "#Setting the optimizer and loss criterion\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "plt.ioff()\n",
        "fig = plt.figure()\n",
        "loss_over_epochs = []\n",
        "accuracy_over_epochs = []\n",
        "\n",
        "#Begin Train\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  epoch_loss, epoch_acc = train(model, optimizer, criterion, epoch+1, NUM_EPOCHS)\n",
        "  loss_over_epochs.append(epoch_loss)\n",
        "  accuracy_over_epochs.append(epoch_acc)\n",
        "  \n",
        "joblib.dump(model, 'model.pkl')\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.ylabel('Train loss')\n",
        "plt.plot(np.arange(NUM_EPOCHS), loss_over_epochs, 'k-')\n",
        "plt.title('train loss and accuracy')\n",
        "plt.xticks(np.arange(NUM_EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(np.arange(NUM_EPOCHS), accuracy_over_epochs, 'b-')\n",
        "plt.ylabel('Train accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.xticks(np.arange(NUM_EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "plt.savefig(\"plot.png\")\n",
        "plt.close(fig)\n",
        "  \n",
        "print(\"Finished Training\")\n",
        "print(\"-\"*10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-wPFYiepBdR",
        "colab_type": "text"
      },
      "source": [
        "#Test and evaluation of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QynJt9lcUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  \n",
        "  label = []\n",
        "  predictions = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "#         print(labels)\n",
        "        label1 = labels.cpu()\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        pred1 = preds.cpu()\n",
        "        if(itr == 0):\n",
        "          predictions.extend(np.array(pred1))\n",
        "          label.extend(np.array(label1))\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "\n",
        "    test_loss /= (3589*repeats)\n",
        "    test_acc /= (3589*repeats)\n",
        "    \n",
        "    predictions = np.array(predictions)\n",
        "    label = np.array(label)\n",
        "\n",
        "    print('Test Loss: %.4f Test Accuracy %.4f' % (test_loss, test_acc))\n",
        "    return predictions, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DfplcjodtC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, label = test(model, criterion)\n",
        "print(predictions, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkEH25MDSpxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9Dtrr0SZxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(predictions, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j191sZTnpROG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  \n",
        "  label = []\n",
        "  predictions = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "#         print(labels)\n",
        "        label1 = labels.cpu()\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        pred1 = preds.cpu()\n",
        "        if(itr == 0):\n",
        "          predictions.extend(np.array(pred1))\n",
        "          label.extend(np.array(label1))\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "\n",
        "    test_loss /= (3589*repeats)\n",
        "    test_acc /= (3589*repeats)\n",
        "    \n",
        "    predictions = np.array(predictions)\n",
        "    label = np.array(label)\n",
        "\n",
        "    print('Test Loss: %.4f Test Accuracy %.4f' % (test_loss, test_acc))\n",
        "    return predictions, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vADGQXT0pVgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, label = test(model, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KysAoIdQsQeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(predictions, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbCUlMk6t04o",
        "colab_type": "text"
      },
      "source": [
        "#Test on Real Photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhMIZmcstz-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install face_recognition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy6u_UQBvVXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.misc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z05mbI3Rvdzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect(image):\n",
        "    if image.shape[2] != 3:\n",
        "        print('...')\n",
        "\n",
        "\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(rgb,\n",
        "    \tmodel = 'cnn')\n",
        "    print(boxes)\n",
        "    images = []\n",
        "    for box in boxes:\n",
        "        img = image[box[0] : box[2] , box[3] : box[1]]\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        images.append(gray)\n",
        "        \n",
        "    for image in images:\n",
        "      print(image)\n",
        "      cv2_imshow(image)\n",
        "        \n",
        "    new_images = []\n",
        "    for image in images:\n",
        "      shape = np.shape(image)\n",
        "      new_image = np.repeat(image, 3)\n",
        "      new_image = new_image.reshape((shape[0], shape[1], 3)).astype('uint8')\n",
        "      new_images.append(new_image)\n",
        "\n",
        "    return new_images, boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8xAZUAnvfDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = cv2.imread('test5.jpg')\n",
        "faces, boxes = np.array(detect(test_img))\n",
        "print(np.shape(faces[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90PEyJ1Yxjem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class test_image(torch.utils.data.Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "    self.transform = transform\n",
        "    test_img = cv2.imread('test5.jpg')\n",
        "    faces, boxes = np.array(detect(test_img))\n",
        "    self.data = faces\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    instance = self.data[index]\n",
        "    img = Image.fromarray(instance)\n",
        "    img = img.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      instance_tensor = self.transform(img)\n",
        "    return instance_tensor\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6iOXiKrz9gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformations = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "dataset = test_image(transform=transformations)\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                                    batch_size=1,\n",
        "                                                    shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao-W64Ge0LY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "with torch.no_grad():\n",
        "  for batch_idx, images in enumerate(dataset_loader):\n",
        "#   outputs = model.forward(images)\n",
        "#   print(outputs)\n",
        "    print(np.shape(np.array(images)))\n",
        "    images = images.cuda()\n",
        "    outputs = model.forward(images)\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    pred1 = preds.cpu()\n",
        "    print(np.array(pred1))\n",
        "    labels.extend(np.array(pred1))\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kUBo-Ca3qro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [5, 3, 3, 3, 3, 4, 3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1xTP4rF5fBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLZKKzfW2bJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "face_list = []\n",
        "for ((top, right, bottom, left), label) in zip(boxes, labels):\n",
        "  cv2.rectangle(test_img, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "  y = top - 15 if top - 15 > 15 else top + 15\n",
        "  cv2.putText(test_img, class_list[label], (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.75, (0, 255, 0), 2)\n",
        "  face_list.append((label, ((top+bottom)/2, (left+right)/2)))\n",
        "\n",
        "print(face_list)\n",
        "# cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "im2 = test_img.copy()\n",
        "# im2[:,:,0] = test_img[:,:,2]\n",
        "# im2[:, :, 2] = test_img[:, :, 0]\n",
        "scipy.misc.imsave('kkk.jpg', imS)\n",
        "cv2_imshow(im2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}